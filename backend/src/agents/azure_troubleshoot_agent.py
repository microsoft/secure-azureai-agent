import semantic_kernel as sk
from semantic_kernel import Kernel
from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion
from semantic_kernel.agents import ChatCompletionAgent, ChatHistoryAgentThread, AzureAIAgent, AzureAIAgentSettings
from semantic_kernel.filters import FunctionInvocationContext
from azure.identity.aio import DefaultAzureCredential
from azure.ai.projects import AIProjectClient
from azure.ai.agents.models import ListSortOrder
from typing import Optional, Dict, Any, AsyncGenerator
import uuid
import logging
import os
import sys
import json
import datetime

# Add the src directory to Python path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from telemetry.setup import get_tracer

# Try to import Key Vault utilities, handle gracefully if not available
try:
    from utils.keyvault import get_secret_from_keyvault
    KEYVAULT_UTILS_AVAILABLE = True
except ImportError:
    logging.warning("Key Vault utilities not available")
    KEYVAULT_UTILS_AVAILABLE = False
    
    def get_secret_from_keyvault(secret_name: str) -> Optional[str]:
        return os.getenv(secret_name)

logger = logging.getLogger(__name__)

class TraceCollector:
    """Collects and formats trace information for agent operations"""
    
    def __init__(self):
        self.operations = []
        self.function_calls = []
        self.current_operation = None
        
    def start_operation(self, operation_name: str, context: Dict[str, Any] = None):
        """Start tracking an operation"""
        self.current_operation = {
            "name": operation_name,
            "start_time": datetime.datetime.now(),
            "context": context or {},
            "completed": False
        }
        
    def complete_operation(self, operation_name: str, result: Dict[str, Any] = None):
        """Complete an operation"""
        if self.current_operation and self.current_operation["name"] == operation_name:
            self.current_operation.update({
                "end_time": datetime.datetime.now(),
                "result": result or {},
                "completed": True
            })
            self.operations.append(self.current_operation.copy())
            self.current_operation = None
            
    def record_function_call(self, function_name: str, arguments: Dict[str, Any], result: Any = None):
        """Record a function call"""
        self.function_calls.append({
            "function": function_name,
            "arguments": arguments,
            "result": result,
            "timestamp": datetime.datetime.now()
        })
        
    def get_current_trace(self) -> Dict[str, Any]:
        """Get current trace information"""
        trace_info = {}
        
        if self.function_calls:
            trace_info["function_calls"] = self.function_calls[-5:]  # Last 5 calls
            
        if self.operations:
            completed_ops = [op for op in self.operations if op["completed"]]
            if completed_ops:
                trace_info["operations"] = completed_ops[-3:]  # Last 3 operations
                
        if self.current_operation:
            trace_info["current_operation"] = self.current_operation
            
        return trace_info if trace_info else None

class AzureTroubleshootAgent:
    """Azure troubleshooting multi-agent system using Semantic Kernel"""
    
    def __init__(self):
        self.ai_service = None
        self.technical_support_agent = None
        self.escalation_agent = None
        self.triage_agent = None
        self.simple_ai_assistant = None
        self.foundry_technical_support_agent = None
        self.sessions: Dict[str, ChatHistoryAgentThread] = {}
        self.tracer = get_tracer()
    
    # Define the auto function invocation filter that will be used by the kernel
    @staticmethod
    async def function_invocation_filter(context: FunctionInvocationContext, next):
        """A filter that will be called for each function call in the response."""
        # Get trace collector from session if available
        trace_collector = getattr(context, '_trace_collector', None)
        
        if "messages" not in context.arguments:
            await next(context)
            return
            
        function_name = context.function.name
        arguments = dict(context.arguments)
        
        print(f"    Agent [{function_name}] called with messages: {arguments.get('messages', 'N/A')}")
        
        # Record function call start
        if trace_collector:
            trace_collector.record_function_call(function_name, arguments)
        
        await next(context)
        
        result_preview = str(context.result.value)[:100] if context.result and context.result.value else "No result"
        print(f"    Response from agent [{function_name}]: {result_preview}")
        
        # Update function call with result
        if trace_collector and trace_collector.function_calls:
            trace_collector.function_calls[-1]["result"] = result_preview
    
    async def initialize(self):
        """Initialize the multi-agent system"""
        with self.tracer.start_as_current_span("agent_initialization"):
            try:
                # Setup Azure OpenAI service using secure credential retrieval
                api_key = get_secret_from_keyvault("AZURE_OPENAI_API_KEY")
                endpoint = get_secret_from_keyvault("AZURE_OPENAI_ENDPOINT") or os.getenv("AZURE_OPENAI_ENDPOINT")
                deployment_name = os.getenv("AZURE_OPENAI_DEPLOYMENT_NAME", "gpt-4")
                project_endpoint = os.getenv("PROJECT_ENDPOINT") or os.getenv("AGENT_API_URL")  # PROJECT_ENDPOINTã‚’å„ªå…ˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§AGENT_API_URL
                foundry_technical_support_agent_id = get_secret_from_keyvault("FOUNDARY_TECHNICAL_SUPPORT_AGENT_ID")
                
                # Check if agent mode is enabled (default: False for agentless mode)
                use_azure_ai_agent = os.getenv("USE_AZURE_AI_AGENT", "false").lower() in ("true", "1", "yes", "on")
                
                if not api_key or not endpoint:
                    raise ValueError("Azure OpenAI credentials not configured")
                
                kernel = Kernel()
                
                # Register the function invocation filter defined on this class
                kernel.add_filter("function_invocation", self.function_invocation_filter)
                
                try:
                    self.ai_service = AzureChatCompletion(
                        deployment_name=deployment_name,
                        endpoint=endpoint,
                        api_key=api_key
                    )
                    logger.info(f"âœ… Azure OpenAI service initialized successfully - Endpoint: {endpoint}")
                except Exception as e:
                    error_msg = f"âŒ Azure OpenAI initialization failed - This may be due to private endpoint restrictions or network connectivity issues. Endpoint: {endpoint}, Error: {str(e)}"
                    logger.error(error_msg)
                    raise ConnectionError(error_msg)
                
                # Initialize based on agent mode
                if use_azure_ai_agent:
                    logger.info("ğŸ¤– Azure AI Agent mode enabled - Initializing Azure AI Foundry agent")
                    try:
                        # Use AIProjectClient for proper Azure AI Agent integration
                        from azure.identity import DefaultAzureCredential as SyncDefaultAzureCredential
                        self.sync_creds = SyncDefaultAzureCredential()
                        self.project_client = AIProjectClient(
                            credential=self.sync_creds,
                            endpoint=project_endpoint
                        )
                        
                        # Get agent definition and initialize
                        self.foundry_agent_def = self.project_client.agents.get_agent(foundry_technical_support_agent_id)
                        logger.info(f"âœ… Azure AI Foundry agent initialized successfully - Project Endpoint: {project_endpoint}")
                        
                        # Store agent ID for later use
                        self.foundry_agent_id = foundry_technical_support_agent_id
                        
                        # Mark that we have a valid AI Foundry setup
                        self.has_foundry_agent = True
                        logger.info("ğŸ¯ Using Azure AI Foundry agent directly via AIProjectClient")
                        
                    except Exception as e:
                        error_msg = f"âŒ Azure AI Foundry initialization failed - This may be due to private endpoint restrictions or network connectivity issues. Project Endpoint: {project_endpoint}, Error: {str(e)}"
                        logger.error(error_msg)
                        # Fall back to agentless mode
                        use_azure_ai_agent = False
                        self.has_foundry_agent = False
                        logger.warning("âš ï¸ Falling back to agentless mode")
                
                if not use_azure_ai_agent:
                    logger.info("ğŸš« Azure AI Agent mode disabled - Running in agentless mode")
                    # Create simple AI assistant for agentless mode
                    self.simple_ai_assistant = ChatCompletionAgent(
                        service=self.ai_service,
                        name="AzureAssistant",
                        instructions="""
                        You are a helpful AI assistant specialized in Azure cloud services and general technical support.
                        
                        You can help users with:
                        - Azure services troubleshooting and configuration
                        - Best practices and recommendations
                        - Error message explanations and solutions
                        - General cloud computing questions
                        - Development and deployment guidance
                        
                        When responding:
                        - Provide clear, accurate, and helpful information
                        - Give step-by-step guidance when appropriate
                        - Suggest relevant Azure documentation when available
                        - Be honest about limitations and recommend escalation when needed
                        - Maintain a friendly and professional tone
                        
                        You are not part of a multi-agent system - respond directly to user queries as a single AI assistant.
                        """
                    )
                    # Set this as the main agent for processing
                    self.triage_agent = self.simple_ai_assistant
                    logger.info("ğŸ¤– Simple AI assistant initialized for agentless mode")
                
                mode = "with Azure AI Foundry agent (direct access)" if use_azure_ai_agent else "in agentless mode with simple AI assistant"
                logger.info(f"âœ… Azure Multi-Agent System initialized successfully {mode}")
                
            except ConnectionError as e:
                # Network connectivity error (likely due to private endpoint restrictions)
                logger.error(f"ğŸ”’ Network connectivity error during initialization: {e}")
                raise
            except Exception as e:
                logger.error(f"âŒ Failed to initialize multi-agent system: {e}")
                raise
    
    async def cleanup(self):
        """Cleanup resources"""
        # Clear sessions
        self.sessions.clear()
        
        # Close AI Project Client if exists
        if hasattr(self, "project_client") and self.project_client:
            # AIProjectClient doesn't have async close, but we can clear the reference
            self.project_client = None
            
        # Close old client if exists (backward compatibility)
        if hasattr(self, "client") and self.client:
            await self.client.close()
        if hasattr(self, "creds") and self.creds:
            await self.creds.close()
            
        logger.info("Multi-agent system cleaned up")
    
    async def _log_thread_details(self, thread: ChatHistoryAgentThread, session_id: str):
        """
        Log thread message details to logs and telemetry.
        
        NOTE: This process is relatively heavy, so it's not called during streaming
        to ensure responsiveness. It's executed after all responses are complete.
        
        Args:
            thread (ChatHistoryAgentThread): The thread to be logged
            session_id (str): The session ID
        """
        try:
            # Get thread message details
            thread_details = await self._extract_thread_details(thread)

            # Log to logger
            logger.info(f"Thread details for session {session_id}:")
            for detail in thread_details:
                logger.info(f"  {detail}")

            # Log to telemetry
            with self.tracer.start_as_current_span("thread_analysis") as span:
                span.set_attribute("session_id", session_id)
                span.set_attribute("message_count", len(thread_details))

                # Message type statistics
                message_types = {}
                for detail in thread_details:
                    msg_type = detail.get("type", "unknown")
                    message_types[msg_type] = message_types.get(msg_type, 0) + 1
                
                for msg_type, count in message_types.items():
                    span.set_attribute(f"message_type_{msg_type}_count", count)

                # Agent usage statistics
                agents_used = set()
                for detail in thread_details:
                    if detail.get("agent_name"):
                        agents_used.add(detail["agent_name"])
                
                span.set_attribute("agents_used", list(agents_used))
                span.set_attribute("unique_agent_count", len(agents_used))

                # Log entire conversation flow to telemetry (for debugging)
                span.add_event("thread_conversation", {
                    "conversation_flow": json.dumps(thread_details, ensure_ascii=False, indent=2)
                })
                
        except Exception as e:
            logger.error(f"Error logging thread details: {e}")
    
    async def _extract_thread_details(self, thread: ChatHistoryAgentThread) -> list:
        """
        Extract detailed information from the thread.
        
        Args:
            thread (ChatHistoryAgentThread): The thread to analyze
            
        Returns:
            list: List of message details
        """
        details = []
        message_index = 0
        
        try:
            async for message in thread.get_messages():
                message_index += 1
                timestamp = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                
                for item in message.items:
                    detail = {
                        "timestamp": timestamp,
                        "message_index": message_index,
                        "ai_model_id": getattr(message, 'ai_model_id', None),
                        "agent_name": getattr(message, 'name', None)
                    }
                    
                    # Function Call Content
                    if hasattr(item, 'name') and hasattr(item, 'arguments'):  # FunctionCallContent
                        detail.update({
                            "type": "function_call",
                            "function_name": item.name,
                            "arguments": str(item.arguments),
                            "description": f"[Function Calling] by {message.ai_model_id or 'unknown'}"
                        })
                    # Function Result Content
                    elif hasattr(item, 'result'):  # FunctionResultContent
                        result_str = str(item.result)
                        try:
                            # JSONå½¢å¼ã®çµæœã‚’ãƒ‘ãƒ¼ã‚¹è©¦è¡Œ
                            decoded_result = json.loads(result_str)
                            result_display = decoded_result
                        except json.JSONDecodeError:
                            result_display = result_str
                        
                        detail.update({
                            "type": "function_result",
                            "result": result_display,
                            "description": "[Function Result]"
                        })
                    
                    # Text Content
                    elif hasattr(item, 'text'):  # TextContent
                        if message.name:
                            msg_type = "agent_response"
                            description = f"[Agent Response] from {message.ai_model_id or 'unknown'}"
                        else:
                            msg_type = "user_message"
                            description = "[User Message]"
                        
                        detail.update({
                            "type": msg_type,
                            "content": item.text,
                            "description": description
                        })
                    
                    # Others
                    else:
                        detail.update({
                            "type": "unknown",
                            "raw_item": str(item),
                            "item_type": type(item).__name__,
                            "description": f"[Unknown Item Type] ({type(item).__name__})"
                        })
                    
                    details.append(detail)
        
        except Exception as e:
            logger.error(f"Error extracting thread details: {e}")
            details.append({
                "timestamp": datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                "type": "error",
                "description": f"Error extracting message details: {str(e)}"
            })
        
        return details
    
    async def print_thread_details(self, session_id: str):
        """
        Output thread details for the specified session to the console (for debugging).
        
        Args:
            session_id (str): Session ID
        """
        thread = self.sessions.get(session_id)
        if not thread:
            print(f"Session {session_id} not found")
            return
        
        print(f"\n=== Thread Details for Session: {session_id} ===")
        
        try:
            async for message in thread.get_messages():
                print("-----")
                
                for item in message.items:
                    # Function Call Content
                    if hasattr(item, 'name') and hasattr(item, 'arguments'):
                        print(f"[Function Calling] by {message.ai_model_id or 'unknown'}")
                        print(f" - Function Name : {item.name}")
                        print(f" - Arguments     : {item.arguments}")
                    
                    # Function Result Content
                    elif hasattr(item, 'result'):
                        print(f"[Function Result]")
                        result_str = str(item.result)
                        try:
                            decoded = json.loads(result_str)
                            print(f" - Result        : {decoded}")
                        except json.JSONDecodeError:
                            print(f" - Result        : {result_str}")
                    
                    # Text Content
                    elif hasattr(item, 'text'):
                        if message.name:
                            print(f"[Agent Response] from {message.ai_model_id or 'unknown'}")
                        else:
                            print("[User Message]")
                        print(f" - Content       : {item.text}")
                    
                    # Others
                    else:
                        print(f"[Unknown Item Type] ({type(item).__name__})")
                        print(f" - Raw Item      : {item}")
            
            print("=== End of Thread Details ===\n")
            
        except Exception as e:
            print(f"Error printing thread details: {e}")
    
    async def get_thread_summary(self, session_id: str) -> Dict[str, Any]:
        """
        Get thread summary for the specified session.
        
        Args:
            session_id (str): Session ID
            
        Returns:
            Dict[str, Any]: Thread summary information
        """
        thread = self.sessions.get(session_id)
        if not thread:
            return {"error": f"Session {session_id} not found"}
        
        try:
            details = await self._extract_thread_details(thread)

            # Collect statistics
            message_types = {}
            agents_used = set()
            total_messages = len(details)
            
            for detail in details:
                msg_type = detail.get("type", "unknown")
                message_types[msg_type] = message_types.get(msg_type, 0) + 1
                
                if detail.get("agent_name"):
                    agents_used.add(detail["agent_name"])
            
            return {
                "session_id": session_id,
                "total_messages": total_messages,
                "message_types": message_types,
                "agents_used": list(agents_used),
                "conversation_details": details
            }
            
        except Exception as e:
            return {"error": f"Error getting thread summary: {str(e)}"}
    
    async def process_message_stream(self, message: str, session_id: Optional[str] = None, mode: str = "chat", enable_trace: bool = False) -> AsyncGenerator[Dict[str, Any], None]:
        """Process a message through the multi-agent system and stream the response
        
        Args:
            message: User message to process
            session_id: Optional session identifier
            mode: Execution mode - "chat" for simple chat, "agent" for full agent capabilities
            enable_trace: Whether to include trace information in the response (agent mode only)
        
        Log and telemetry recording is executed after streaming is complete.
        During streaming, responsiveness is prioritized and no log recording is performed.
        """
        if session_id is None:
            session_id = str(uuid.uuid4())

        with self.tracer.start_as_current_span("process_message_stream") as span:
            span.set_attribute("session_id", session_id)
            span.set_attribute("message_length", len(message))
            span.set_attribute("mode", mode)
            span.set_attribute("enable_trace", enable_trace)
            
            # Initialize trace collector for agent mode
            trace_collector = TraceCollector() if enable_trace and mode == "agent" else None
            
            try:
                # Get or create thread for this session
                thread = self.sessions.get(session_id)
                if thread is None:
                    thread = ChatHistoryAgentThread()
                
                # Route based on mode
                if mode == "agent":
                    # Full agent mode with multi-agent capabilities
                    
                    # Check if agent mode is enabled via environment variable
                    use_azure_ai_agent = os.getenv("USE_AZURE_AI_AGENT", "false").lower() in ("true", "1", "yes", "on")
                    if not use_azure_ai_agent:
                        error_msg = """ğŸ¤– **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ãŒç„¡åŠ¹ã§ã™**

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ã®è¨­å®šãŒå¿…è¦ã§ã™ï¼š

**ç’°å¢ƒå¤‰æ•°ã®è¨­å®š:**
- `USE_AZURE_AI_AGENT=true` ã‚’è¨­å®šã—ã¦ãã ã•ã„
- `PROJECT_ENDPOINT` - AI Foundryãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- `FOUNDARY_TECHNICAL_SUPPORT_AGENT_ID` - Foundryã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆID

**ç¾åœ¨ã®çŠ¶æ³:**
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ãƒ•ãƒ©ã‚°: ç„¡åŠ¹ âŒ
- åŸºæœ¬ã®ãƒãƒ£ãƒƒãƒˆæ©Ÿèƒ½ã¯åˆ©ç”¨å¯èƒ½ã§ã™ ğŸ’¬

**å¯¾å‡¦æ–¹æ³•:**
1. ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ç’°å¢ƒå¤‰æ•°ã®è¨­å®šã‚’ä¾é ¼ã—ã¦ãã ã•ã„
2. è¨­å®šå¾Œã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„
3. ã¾ãŸã¯ã€ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã§åŸºæœ¬çš„ãªAIæ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„

è©³ç´°ã¯ç®¡ç†è€…å‘ã‘ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚"""
                        logger.warning(f"Agent mode requested but USE_AZURE_AI_AGENT flag is disabled for session {session_id}")
                        yield {
                            "content": error_msg,
                            "session_id": session_id,
                            "is_done": True,
                            "mode": mode
                        }
                        return
                    
                    # Check if we have a properly initialized AI Foundry agent
                    if not hasattr(self, 'has_foundry_agent') or not self.has_foundry_agent:
                        error_msg = """ğŸ”’ **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“**

ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã®åˆæœŸåŒ–ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ä»¥ä¸‹ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ï¼š

**è€ƒãˆã‚‰ã‚Œã‚‹åŸå› :**
- AI Foundryãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã®æ¥ç¶šã‚¨ãƒ©ãƒ¼
- ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã®ä¸å‚™
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã®å•é¡Œ

**å¯¾å‡¦æ–¹æ³•:**
1. ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¦åŸºæœ¬æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„
2. ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã®ç¢ºèªã‚’ä¾é ¼ã—ã¦ãã ã•ã„
3. ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„"""
                        logger.error(error_msg)
                        yield {
                            "content": error_msg,
                            "session_id": session_id,
                            "is_done": True,
                            "mode": mode
                        }
                        return
                    
                    # Use AI Project Client for agent communication
                    logger.info(f"Processing in agent mode for session {session_id}")
                    
                    try:
                        # Create a thread for this conversation
                        ai_thread = self.project_client.agents.threads.create()
                        logger.debug(f"Created AI thread: {ai_thread.id}")
                        
                        # Add user message to thread
                        self.project_client.agents.messages.create(
                            thread_id=ai_thread.id,
                            role="user",
                            content=message
                        )
                        
                        # Run the agent
                        run = self.project_client.agents.runs.create_and_process(
                            thread_id=ai_thread.id,
                            agent_id=self.foundry_agent_id
                        )
                        
                        if run.status == "failed":
                            error_msg = f"ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {run.last_error}"
                            logger.error(error_msg)
                            yield {
                                "content": error_msg,
                                "session_id": session_id,
                                "is_done": True,
                                "mode": mode
                            }
                            return
                        
                        # Get messages from thread
                        messages = self.project_client.agents.messages.list(
                            thread_id=ai_thread.id, 
                            order=ListSortOrder.ASCENDING
                        )
                        
                        # Stream agent response
                        for msg in messages:
                            if msg.role == "assistant" and msg.text_messages:
                                content = msg.text_messages[-1].text.value
                                yield {
                                    "content": content,
                                    "session_id": session_id,
                                    "is_done": False,
                                    "mode": mode
                                }
                                
                    except Exception as agent_e:
                        error_msg = f"ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆé€šä¿¡ã‚¨ãƒ©ãƒ¼: {str(agent_e)}"
                        logger.error(f"Agent communication error: {agent_e}")
                        yield {
                            "content": error_msg,
                            "session_id": session_id,
                            "is_done": True,
                            "mode": mode
                        }
                        return
                        
                elif mode == "chat":
                    # Simple chat mode using direct AI service
                    logger.info(f"Processing in chat mode for session {session_id}")
                    
                    if not self.simple_ai_assistant:
                        # Create a simple assistant if not available
                        if not self.ai_service:
                            error_msg = "ğŸ”’ Chat service not initialized"
                            logger.error(error_msg)
                            yield {
                                "content": error_msg,
                                "session_id": session_id,
                                "is_done": True,
                                "mode": mode
                            }
                            return
                        
                        self.simple_ai_assistant = ChatCompletionAgent(
                            service=self.ai_service,
                            name="SimpleAssistant",
                            instructions="""
                            You are a helpful AI assistant specializing in Azure and technical support.
                            Provide clear, concise, and helpful responses to user questions.
                            Focus on practical solutions and best practices.
                            If you don't know something, acknowledge it honestly and suggest where to find more information.
                            """
                        )
                    
                    try:
                        async for response in self.simple_ai_assistant.invoke_stream(thread=thread, messages=message):
                            if hasattr(response, 'content') and response.content:
                                content = str(response.content)
                                yield {
                                    "content": content,
                                    "session_id": session_id,
                                    "is_done": False,
                                    "mode": mode
                                }
                            
                            if hasattr(response, 'thread'):
                                thread = response.thread
                                
                    except Exception as chat_e:
                        logger.error(f"Error in chat mode: {chat_e}")
                        yield {
                            "content": f"ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(chat_e)}",
                            "session_id": session_id,
                            "is_done": True,
                            "mode": mode
                        }
                        return
                
                else:
                    # Invalid mode
                    error_msg = f"ç„¡åŠ¹ãªãƒ¢ãƒ¼ãƒ‰: {mode}. 'chat' ã¾ãŸã¯ 'agent' ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"
                    logger.error(error_msg)
                    yield {
                        "content": error_msg,
                        "session_id": session_id,
                        "is_done": True,
                        "mode": mode
                    }
                    return
                
                # Post-streaming processing: session storage and log recording
                # Store the final thread state
                self.sessions[session_id] = thread
                
                # Log thread details for debugging and telemetry (executed after streaming completion)
                await self._log_thread_details(thread, session_id)
                
                # Send completion signal with trace information if available
                completion_data = {
                    "content": "",
                    "session_id": session_id,
                    "is_done": True,
                    "mode": mode
                }
                
                # Add final trace information if enabled
                if trace_collector:
                    final_trace = trace_collector.get_current_trace()
                    if final_trace:
                        completion_data["trace"] = final_trace
                
                yield completion_data
                
            except ConnectionError as e:
                # Network connectivity error (likely due to private endpoint restrictions)
                error_msg = f"ğŸ”’ æ¥ç¶šã‚¨ãƒ©ãƒ¼: Azure OpenAIã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šï¼ˆPrivate Endpointï¼‰ã«ã‚ˆã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚è©³ç´°: {str(e)}"
                logger.error(f"ğŸ”’ Network connectivity error in message stream: {e}")
                span.record_exception(e)
                yield {
                    "content": error_msg,
                    "session_id": session_id,
                    "is_done": True,
                    "mode": mode
                }
            except Exception as e:
                # Check if the error is related to Azure OpenAI connectivity
                error_str = str(e).lower()
                if any(keyword in error_str for keyword in ['connection', 'network', 'timeout', 'unreachable', 'forbidden', '403', '404', 'dns']):
                    error_msg = f"ğŸ”’ æ¥ç¶šã‚¨ãƒ©ãƒ¼: Azure OpenAIã‚µãƒ¼ãƒ“ã‚¹ã¸ã®æ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚è©³ç´°: {str(e)}"
                    logger.error(f"ğŸ”’ Potential network connectivity error in message stream: {e}")
                elif mode == "agent" and any(keyword in error_str for keyword in ['agent', 'foundry', 'project']):
                    error_msg = f"ğŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: AI Foundryã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®æ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆè¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚è©³ç´°: {str(e)}"
                    logger.error(f"ğŸ¤– Agent mode error in message stream: {e}")
                else:
                    error_msg = f"ã‚¨ãƒ©ãƒ¼: {str(e)}"
                    logger.error(f"âŒ Error in message stream: {e}")
                
                span.record_exception(e)
                yield {
                    "content": error_msg,
                    "session_id": session_id,
                    "is_done": True,
                    "mode": mode
                }
