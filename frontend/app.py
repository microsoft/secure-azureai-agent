import chainlit as cl
import httpx
import os
import json
import asyncio
from typing import Optional, Dict, Any
import logging

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Backend API configuration
BACKEND_API_URL = os.getenv("BACKEND_API_URL", "http://localhost:8000")

class BackendAPIClient:
    """Client for communicating with the backend API"""
    
    def __init__(self):
        self.base_url = BACKEND_API_URL
    
    async def send_message_stream(self, message: str, session_id: Optional[str] = None, mode: str = "chat", enable_trace: bool = False):
        """Send message to backend API and stream response"""
        async with httpx.AsyncClient(timeout=60.0) as client:
            try:
                payload = {
                    "message": message,
                    "session_id": session_id,
                    "mode": mode,  # Add mode parameter
                    "enable_trace": enable_trace  # Add trace parameter
                }
                
                logger.info(f"Sending request with mode: {mode}, trace: {enable_trace}")
                
                async with client.stream(
                    "POST",
                    f"{self.base_url}/api/chat/stream",
                    json=payload,
                    headers={"Accept": "text/event-stream"}
                ) as response:
                    response.raise_for_status()
                    
                    async for line in response.aiter_lines():
                        if line.startswith("data: "):
                            data = line[6:]  # Remove "data: " prefix
                            try:
                                yield json.loads(data)
                            except json.JSONDecodeError:
                                continue
                                
            except httpx.ConnectError as e:
                logger.error(f"ðŸ”’ Connection error to backend: {e}")
                yield {
                    "content": "ðŸ”’ æŽ¥ç¶šã‚¨ãƒ©ãƒ¼: ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã«æŽ¥ç¶šã§ãã¾ã›ã‚“ã€‚ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŽŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
                    "session_id": session_id or "error",
                    "is_done": True
                }
            except httpx.TimeoutException as e:
                logger.error(f"ðŸ”’ Timeout error: {e}")
                yield {
                    "content": "ðŸ”’ ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹ã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã€‚ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŽŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
                    "session_id": session_id or "error",
                    "is_done": True
                }
            except httpx.HTTPStatusError as e:
                logger.error(f"HTTP status error: {e}")
                if e.response.status_code == 500:
                    yield {
                        "content": "ðŸ”’ ã‚µãƒ¼ãƒ“ã‚¹ã‚¨ãƒ©ãƒ¼: Azure OpenAIã‚µãƒ¼ãƒ“ã‚¹ã¨ã®æŽ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šï¼ˆPrivate Endpointï¼‰ã«ã‚ˆã‚‹ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŽŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚",
                        "session_id": session_id or "error",
                        "is_done": True
                    }
                else:
                    yield {
                        "content": f"âŒ HTTPã‚¨ãƒ©ãƒ¼: {e.response.status_code} - {e.response.text}",
                        "session_id": session_id or "error",
                        "is_done": True
                    }
            except httpx.HTTPError as e:
                logger.error(f"HTTP error in streaming: {e}")
                yield {
                    "content": f"ðŸ”’ é€šä¿¡ã‚¨ãƒ©ãƒ¼: {str(e)} - ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŽŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚",
                    "session_id": session_id or "error",
                    "is_done": True
                }
            except Exception as e:
                logger.error(f"Error in streaming: {e}")
                yield {
                    "content": f"âŒ äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {str(e)}",
                    "session_id": session_id or "error",
                    "is_done": True
                }
    
    async def health_check(self):
        """Check if backend is healthy"""
        async with httpx.AsyncClient(timeout=10.0) as client:
            try:
                response = await client.get(f"{self.base_url}/health")
                if response.status_code == 200:
                    health_data = response.json()
                    if health_data.get("status") == "degraded":
                        logger.warning(f"Backend service is degraded: {health_data.get('message', 'Unknown issue')}")
                    return True
                return False
            except httpx.ConnectError as e:
                logger.error(f"ðŸ”’ Connection error during health check: {e}")
                return False
            except httpx.TimeoutException as e:
                logger.error(f"ðŸ”’ Timeout during health check: {e}")
                return False
            except Exception as e:
                logger.error(f"Health check failed: {e}")
                return False

# Global API client
api_client = BackendAPIClient()

@cl.on_chat_start
async def on_chat_start():
    """Initialize chat session"""
    logger.info("Starting new chat session")
    
    # Set up mode selection for the session
    settings = await cl.ChatSettings([
        cl.input_widget.Select(
            id="mode",
            label="ðŸ¤– å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰",
            values=["chat", "agent"],
            initial_index=0,
            tooltip="ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰: ã‚·ãƒ³ãƒ—ãƒ«ãªä¼šè©±åž‹AI\nã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰: AI Foundryã®é«˜åº¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã‚’ä½¿ç”¨"
        ),
        cl.input_widget.Switch(
            id="enable_trace",
            label="ðŸ” ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹•ä½œã®ãƒˆãƒ¬ãƒ¼ã‚¹è¡¨ç¤º",
            initial=False,
            tooltip="ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã§ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚„æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã‚’è¡¨ç¤º"
        )
    ]).send()
    
    # Store initial mode in session
    cl.user_session.set("mode", "chat")
    cl.user_session.set("enable_trace", False)
    cl.user_session.set("session_history", [])  # Track conversation history across mode changes
    
    # Welcome message
    welcome_message = """ðŸš€ **Azure AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ** ã¸ã‚ˆã†ã“ãï¼

**å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰:**
- ðŸ“ **ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰**: ã‚·ãƒ³ãƒ—ãƒ«ãªä¼šè©±åž‹AIã¨ã—ã¦ã”è³ªå•ã«ãŠç­”ãˆã—ã¾ã™
- ðŸ¤– **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰**: AI Foundryã®é«˜åº¦ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ã€å°‚é–€çš„ãªãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã—ã¦ã‚µãƒãƒ¼ãƒˆã—ã¾ã™

**è¨­å®šå¤‰æ›´:**
å³ä¸Šã®è¨­å®šãƒœã‚¿ãƒ³ï¼ˆâš™ï¸ï¼‰ã‹ã‚‰ãƒ¢ãƒ¼ãƒ‰ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚

âš ï¸ **æ³¨æ„**: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ç®¡ç†è€…ã«ã‚ˆã‚‹ç’°å¢ƒè¨­å®šãŒå¿…è¦ã§ã™ã€‚è¨­å®šãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã¯ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚

**å¾—æ„åˆ†é‡Ž:**
â€¢ **AzureæŠ€è¡“ã‚µãƒãƒ¼ãƒˆ** - Azureã‚µãƒ¼ãƒ“ã‚¹ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã¨ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹
â€¢ **ã‚·ã‚¹ãƒ†ãƒ è¨ºæ–­** - æŠ€è¡“çš„å•é¡Œã®ç‰¹å®šã¨ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
â€¢ **æœ€é©åŒ–ææ¡ˆ** - ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹æ”¹å–„ã¨ãƒªã‚½ãƒ¼ã‚¹æœ€é©åŒ–ã®ã‚¢ãƒ‰ãƒã‚¤ã‚¹

ã”è³ªå•ã‚’ãŠèžã‹ã›ãã ã•ã„ï¼"""
    
    await cl.Message(content=welcome_message).send()
    
    # Store session information
    cl.user_session.set("session_started", True)

@cl.on_settings_update
async def on_settings_update(settings: Dict[str, Any]):
    """Handle settings updates"""
    old_mode = cl.user_session.get("mode", "chat")
    new_mode = settings.get("mode", "chat")
    enable_trace = settings.get("enable_trace", False)
    
    # Update session with new settings
    cl.user_session.set("mode", new_mode)
    cl.user_session.set("enable_trace", enable_trace)
    
    logger.info(f"Settings updated - Old mode: {old_mode}, New mode: {new_mode}, Trace: {enable_trace}")
    
    # Send confirmation message
    mode_display = "ðŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰" if new_mode == "agent" else "ðŸ“ ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰"
    trace_display = "æœ‰åŠ¹" if enable_trace else "ç„¡åŠ¹"
    
    # Check if mode changed
    mode_change_msg = ""
    if old_mode != new_mode:
        mode_change_msg = f"\n\nâš¡ ãƒ¢ãƒ¼ãƒ‰ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ: {old_mode} â†’ {new_mode}\nä¼šè©±å±¥æ­´ã¯ç¶™ç¶šã•ã‚Œã¾ã™ã€‚"
        
        # Add warning for agent mode
        if new_mode == "agent":
            mode_change_msg += f"""
            
âš ï¸ **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã«ã¤ã„ã¦:**
ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ã‚ˆã‚‹ä»¥ä¸‹ã®è¨­å®šãŒå¿…è¦ã§ã™ï¼š
- `USE_AZURE_AI_AGENT=true` ç’°å¢ƒå¤‰æ•°ã®è¨­å®š
- AI Foundryãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æŽ¥ç¶šè¨­å®š

è¨­å®šãŒå®Œäº†ã—ã¦ã„ãªã„å ´åˆã¯ã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚
ãã®å ´åˆã¯ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã§ã®åŸºæœ¬æ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„ã€‚"""
    
    await cl.Message(
        content=f"âš™ï¸ è¨­å®šãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸ:\n- å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰: {mode_display}\n- ãƒˆãƒ¬ãƒ¼ã‚¹è¡¨ç¤º: {trace_display}{mode_change_msg}"
    ).send()

@cl.on_message
async def on_message(message: cl.Message):
    """Handle incoming messages"""
    logger.info(f"Received message: {message.content[:100]}...")
    
    # Get current mode and trace settings from session
    current_mode = cl.user_session.get("mode", "chat")
    enable_trace = cl.user_session.get("enable_trace", False)
    
    # Get session ID (use Chainlit's session ID)
    session_id = cl.user_session.get("id")
    
    # Create response message
    response_msg = cl.Message(content="")
    
    try:
        # Check if backend is available by making a simple request first
        if not await api_client.health_check():
            await cl.Message(
                content="ðŸ”’ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŽŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
            ).send()
            return
            
    except Exception as e:
        logger.error(f"Backend health check failed: {e}")
        await cl.Message(
            content="ðŸ”’ ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚µãƒ¼ãƒ“ã‚¹ã«æŽ¥ç¶šã§ãã¾ã›ã‚“ã€‚ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŽŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
        ).send()
        return
    
    # Show mode indicator
    mode_indicator = "ðŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰" if current_mode == "agent" else "ðŸ“ ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰"
    status_msg = await cl.Message(content=f"{mode_indicator} ã§å‡¦ç†ä¸­...").send()
    
    # Initialize trace messages list for agent mode
    trace_messages = []
    
    try:
        # Use streaming for better user experience with current mode
        async for chunk in api_client.send_message_stream(
            message=message.content,
            session_id=session_id,
            mode=current_mode,
            enable_trace=enable_trace
        ):
            if chunk.get("content"):
                await response_msg.stream_token(chunk["content"])
            
            # Handle trace information if available and enabled
            if enable_trace and current_mode == "agent" and chunk.get("trace"):
                trace_data = chunk["trace"]
                trace_content = await format_trace_data(trace_data)
                if trace_content:
                    trace_messages.append(trace_content)
            
            if chunk.get("is_done", False):
                break
        
        # Remove status message after processing is complete
        await status_msg.remove()
        
        # Send the final message
        await response_msg.send()
        
        # Send trace information as separate expandable messages if enabled
        if enable_trace and current_mode == "agent" and trace_messages:
            for trace_msg in trace_messages:
                await cl.Message(
                    content=trace_msg,
                    elements=[cl.Text(name="trace", content=trace_msg, display="side")]
                ).send()
        
    except Exception as e:
        logger.error(f"Error processing message: {e}")
        
        # Remove status message in case of error
        try:
            await status_msg.remove()
        except:
            pass  # Ignore if message already removed
        
        # Check if the error is network-related
        error_str = str(e).lower()
        if any(keyword in error_str for keyword in ['connection', 'network', 'timeout', 'unreachable', 'forbidden']):
            error_message = "ðŸ”’ æŽ¥ç¶šã‚¨ãƒ©ãƒ¼: ã‚µãƒ¼ãƒ“ã‚¹ã¨ã®é€šä¿¡ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚ã“ã‚Œã¯é–‰åŸŸåŒ–è¨­å®šã‚„ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ¶é™ãŒåŽŸå› ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯è¨­å®šã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
        elif current_mode == "agent" and any(keyword in error_str for keyword in ['agent', 'foundry', 'project']):
            error_message = f"ðŸ¤– ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: AI Foundryã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã¨ã®æŽ¥ç¶šã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚\n\n**å¯¾å‡¦æ–¹æ³•:**\n1. ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆã¦åŸºæœ¬çš„ãªæ©Ÿèƒ½ã‚’ã”åˆ©ç”¨ãã ã•ã„\n2. AI Foundryãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„\n3. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæŽ¥ç¶šæƒ…å ±ãŒæ­£ã—ãè¨­å®šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„\n\nè©³ç´°: {str(e)}"
        elif current_mode == "agent" and "trace" in error_str:
            error_message = f"ðŸ” ãƒˆãƒ¬ãƒ¼ã‚¹æ©Ÿèƒ½ã‚¨ãƒ©ãƒ¼: ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ãƒˆãƒ¬ãƒ¼ã‚¹è¡¨ç¤ºã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚åŸºæœ¬çš„ãªã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆæ©Ÿèƒ½ã¯å‹•ä½œã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚\n\nè©³ç´°: {str(e)}"
        else:
            error_message = f"âŒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        
        await cl.Message(content=error_message).send()

async def format_trace_data(trace_data: Dict[str, Any]) -> Optional[str]:
    """Format trace data for display"""
    if not trace_data:
        return None
    
    trace_lines = ["ðŸ” **ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå‹•ä½œãƒˆãƒ¬ãƒ¼ã‚¹:**"]
    
    if trace_data.get("function_calls"):
        trace_lines.append("\nðŸ“ž **ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—:**")
        for call in trace_data["function_calls"]:
            function_name = call.get("function", "Unknown")
            arguments = call.get("arguments", {})
            result = call.get("result", "No result")
            
            trace_lines.append(f"- **{function_name}**")
            if arguments:
                trace_lines.append(f"  - å¼•æ•°: `{json.dumps(arguments, ensure_ascii=False, indent=2)}`")
            if result:
                trace_lines.append(f"  - çµæžœ: `{str(result)[:200]}{'...' if len(str(result)) > 200 else ''}`")
    
    if trace_data.get("thought_process"):
        trace_lines.append("\nðŸ§  **æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹:**")
        for step in trace_data["thought_process"]:
            trace_lines.append(f"- {step}")
    
    if trace_data.get("decision_making"):
        trace_lines.append("\nâš–ï¸ **æ„æ€æ±ºå®š:**")
        for decision in trace_data["decision_making"]:
            trace_lines.append(f"- {decision}")
    
    return "\n".join(trace_lines) if len(trace_lines) > 1 else None

@cl.on_chat_end
async def on_chat_end():
    """Clean up when chat ends"""
    logger.info("Chat session ended")
    # Don't close the client here as it might be reused
    # await api_client.close()

if __name__ == "__main__":
    # For local development, you can run this directly
    port = int(os.getenv("PORT", 8501))
    
    # Run Chainlit app
    # Note: In production, use chainlit CLI commands instead
    logger.info(f"Starting Chainlit app on port {port}")
    
    # This is a placeholder - in practice, use: chainlit run app.py --port {port}
    print(f"To run this app, use: chainlit run app.py --port {port}")
